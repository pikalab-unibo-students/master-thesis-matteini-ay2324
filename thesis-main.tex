\documentclass[12pt,a4paper,openright,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage{disi-thesis}
\usepackage{code-lstlistings}
\usepackage{notes}
\usepackage{shortcuts}
\usepackage{acronym}
\usepackage[inline]{enumitem}


\school{\unibo}
\programme{Corso di Laurea Magistrale in Ingegneria e Scienze Informatiche}
% \title{Addressing Fairness in \ac{AI} Systems:\newline a Pragmatic (Meta-)Methodology and its Reification into a Software System}
\title{Addressing Fairness in \acs{AI} Systems: Design and Development of a Pragmatic (Meta-)Methodology}
% \title{Addressing Fairness in \ac{AI} Systems: a Pragmatic (Meta-)Methodology from an Engineering Perspective}
\author{Mattia Matteini}
\date{\today}
\subject{Intelligent Systems Engineering}
\supervisor{Prof.\ Giovanni Ciatto}
\cosupervisor{Prof.\ Roberta Calegari}
\morecosupervisor{Prof.\ Andrea Omicini}

\session{IV}
\academicyear{2023--2024}

% Definition of acronyms
\acrodef{AI}{Artificial Intelligence}
\acrodef{BU}{Business User}
\acrodef{TU}{Technical User}
\acrodef{Q/A}{Question--Answering}

% temporary fix for acronyms (https://github.com/oetiker/acronym/issues/62)
\makeatletter
\AtBeginDocument
 {
   \def\ltx@label#1{\cref@label{#1}}%add braces
   \def\label@in@display@noarg#1{\cref@old@label@in@display{#1}}%remove braces  
 } %
\makeatother

% \acrodef{IoT}{Internet of Thing}
% \acrodef{vm}[VM]{Virtual Machine}

% You can use acronyms that your defined previously,
% such as \ac{IoT}.
% %
% If you use acronyms twice,
% they will be written in full only once
% (indeed, you can mention the \ac{IoT} now without it being fully explained).
% %
% In some cases, you may need a plural form of the acronym.
% %
% For instance, that you are discussing \acp{vm},
% you may need both \ac{vm} and \acp{vm}.

\mainlinespacing{1.241} % line spacing in mainmatter, comment to default (1)

\begin{document}

\frontmatter\frontispiece

\begin{abstract}	
Max 2000 characters, strict.
\end{abstract}


\begin{dedication} % this is optional
Optional. Max a few lines.
\end{dedication}

%----------------------------------------------------------------------------------------
\tableofcontents   
\listoffigures     % (optional) comment if empty
\lstlistoflistings % (optional) comment if empty
%----------------------------------------------------------------------------------------

\mainmatter

%----------------------------------------------------------------------------------------
\chapter{Introduction}\label{chap:introduction}
%----------------------------------------------------------------------------------------


\paragraph{Structure of the Thesis}

\note{At the end, describe the structure of the paper}




%----------------------------------------------------------------------------------------
\chapter{Background}\label{chap:background}
%----------------------------------------------------------------------------------------

\section{What is Fairness?}
%
% 1. explaining what is normal fairness, from an ethical and social perspective
%
Fairness, from an ethical and social perspective, is the principle of treating individuals and groups equitably, ensuring that no one is unjustly advantaged or disadvantaged due to biases, discrimination, or arbitrary distinctions.
%
It is deeply rooted in moral philosophy, legal systems, and societal norms, aiming to promote justice, equality, and inclusion.
%
A just society requires reducing social inequalities, and ensuring that opportunities and resources are distributed in a way that acknowledges both individual merit and systemic disadvantages.
%
The concept of fairness evolves based on cultural, historical, and contextual factors, reflecting a society’s commitment to ethical treatment and social cohesion.


\paragraph{Fairness in \acs{AI}.}

% 2. explaining what is fairness in AI, from a technical perspective
From a technical point of view, fairness in \ac{AI} refers to the development and deployment of \ac{AI} systems that minimize biases and prevent discriminatory outcomes.
%
It involves designing systems that ensure equitable treatment across different demographic groups, particularly those historically marginalized or disadvantaged.
%
% Fairness in AI can be assessed using various mathematical definitions, such as demographic parity, equalized odds, and fairness through unawareness, depending on the context and application.
%
The main challenges in this field are building \texttt{fair-by-design} systems, namely such systems in which the fairness problem is addressed since the very beginning of the process, and detecting biases in already existing systems, mitigating them if possible.
%
% The challenge in AI fairness lies in defining and balancing these technical fairness measures while maintaining model accuracy and practical utility.

Before the advent of fairness, \ac{AI} systems were developed with the primary goal of optimizing performance metrics, such as accuracy and efficiency. Nowadays, that fairness is becoming a crucial aspect to consider, accuracy is no more the only metric to optimize, it is necessary to find a balance between accuracy and fairness. Besides that, fairness can also be in contrast with the performance of the model, making difficult to find a good trade-off between these two aspects.

% 3. explaining why fairness in AI is important
Fairness is becoming crucial because \ac{AI} systems increasingly influence decision-making processes in various sectors of society, including hiring, lending and healthcare.
%
If \ac{AI} models are biased, they can perpetuate and even amplify existing societal inequalities, leading to unjust outcomes and tremendous effects on individuals and communities.
%
Ensuring fairness in \ac{AI} enhances trust, transparency, and accountability, making \ac{AI} systems more ethical, reliable, and beneficial for society.

% 3.1 speaking about some history of AI and the fact is getting more and more important and utilized in many fields
\ac{AI} has undergone significant advancements over the past few decades, causing an enormous increase in its adoption across various domains, until becoming pervasive in the daily life of people.
%
This also caused a growing of biases in \ac{AI} systems, as discriminations are intrinsically part of the human history, and consequently of the data that \ac{AI} systems are trained on.


% 3.2 speaking about the fact that AI is used in many critical fields, and the fact that fairness is important in these fields

\ac{AI} is now widely used in critical domains such as healthcare, finance, education, and criminal justice, where biased decisions can have life-altering consequences.
%
For instance, in healthcare, biased algorithms may lead to misdiagnosis or unequal treatment recommendations for different demographic groups;
%
in finance, \ac{AI}-driven credit scoring models can reinforce discriminatory lending practices, limiting access to financial resources;
%
in the criminal justice system, biased predictive policing and risk assessment tools can disproportionately target marginalized communities.
%
Given these risks, ensuring fairness in \ac{AI} is essential to preventing discrimination, maintaining ethical standards, and safeguarding individuals.


\paragraph{On Multidisciplinarity.}

% 4. AI fairness is a multidisciplinary concept.

Achieving fairness in \ac{AI} requires a multidisciplinary approach that integrates insights from computer science, ethics, law and social sciences.
%
Technical methods alone cannot fully address fairness, as fairness is deeply tied to societal values, human rights, and legal frameworks.
%
Socio-legal experts help define fairness principles, ensure compliance with anti-discrimination laws and analyze the societal impact.
%
The intersection of these fields highlights that \ac{AI} fairness is not merely a technical challenge but a complex, multidimensional issue requiring collective effort and interdisciplinary research and collaboration.

% 4.1 explaining the link with the socio-legal perspective and contraints, citing AI Act

An impactful example regarding the work of legal experts in the field of \acl{AI} is the \textit{AI Act}. \sidenote{add some citation}
%
The AI Act, proposed by the European Union, is a comprehensive regulatory framework designed to ensure that AI systems are safe, transparent, and aligned with fundamental rights.
%
It categorizes AI applications into different risk levels—unacceptable risk, high risk, limited risk, and minimal risk—imposing stricter requirements on higher-risk systems, such as those used in hiring, law enforcement, and healthcare.
%
These requirements include transparency, human oversight, and bias mitigation. However, translating these legal constraints into practical technical steps is not trivial. 

Concepts like fairness, accountability, and explainability are difficult to quantify, and AI models often operate as black boxes, making compliance complex.
%
While the AI Act sets an important precedent for AI governance, its effective implementation requires further collaboration between policymakers, legal experts, and computer scientist to bridge the gap between regulation and technical feasibility.


\paragraph{Measuring Fairness.}
% 5. How to assess and measure fairness?

At one point, in order to assess the fairness of an \ac{AI} system, is important to have a way to ``measure'' how much the system is fair and in what terms.
%
Remarking what said before, fairness is very context-dependent, and there is not a single way to measure it. 

% 5.1 define fairness metrics

The need to cover multiple aspects of fairness has led to the introduction of various \textit{fairness metrics}---statistical formulas that quantify fairness in different ways, each capturing a slightly different aspect of fairness.
%
These fairness metrics, are a set of indexes that can be used to detect biases in \ac{AI} systems, and they can be used indeed to evaluate the fairness of a model.
%

% 5.2 list the main fariness matrics providing a brief description and formal definition

In the following, are listed some of the most common fairness metrics used in the literature (\cite{DBLP:conf/bias/IrfanML23}):

\begin{itemize}
    \item \textit{Statistical Parity Difference} (SPD) measures the difference between the probability of the privileged and unprivileged classes receiving a favorable outcome. This measure should be equal to 0 to be fair.
    
    Formally it is defined as $SPD = P(\hat{Y} = 1 | A = a) - P(\hat{Y} = 1 | A = b)$
    %
    where $A$ is the sensitive attribute, $\hat{Y}$ is the predicted outcome, and $a$ and $b$ are the privileged and unprivileged groups, respectively.
    
    \item \textit{Disparate Impact} (DI) compares the proportion of individuals that receive a favorable outcome for two groups, a privileged group and an unprivileged group. This measure should be equal to 1 to be fair.
    
    Formally it is defined as $DI = P(\hat{Y} = 1 | A = a) / P(\hat{Y} = 1 | A = b)$
    %
    where $A$ is the sensitive attribute, $\hat{Y}$ is the predicted outcome, and $a$ and $b$ are the privileged and unprivileged groups, respectively.
    \sidenote{add more metrics?}
    
\end{itemize}


\note{manca una sezione Lack of engineering methodology?}


\section{\acs{AI} Lifecycle}

% 1. AI lifecycle changes a lot if we consider fairness, speak about lifecycle in general, and speak about the changes that fairness introduces

Since the very beginning of the \ac{AI} era, the standard lifecycle consists of the following ``traditional'' steps:
\begin{enumerate*}[label= (\roman*)]
    \item data collection and processing,
    \item model training,
    \item system evaluation.
\end{enumerate*}
%
Obviously, this workflow in the latest years have increased in complexity and now, with the newer innovations and powerful models and architectures, it may appear even almost minimalistic, but it still represents the core of all \ac{AI} systems.

However, when fairness is taken into account, each step needs to be revisited in order to obtain an equitable, impartial, and fair \ac{AI} system.

% 2 fairness can be achieved only if socio-legal perspective is taken into account, talk about the importance of the socio-legal perspective

To achieve this goal, the technical perspective is not enough. 
Fairness is a multidisciplinary concept that involves social, legal, and ethical aspects.
%
Therefore, the \ac{AI} lifecycle needs to be constrained by socio-legal requirements that engineers must consider during the development process.
%
This includes understanding the societal impact of \ac{AI} systems, ensuring compliance with legal standards, and adhering to ethical guidelines.

There are also many differences between the socio-legal and technical perspectives. Regarding the \ac{AI} lifecycle, engineers tend to focus on technical aspects and few development phases, in fact the major part of the literature speaks only about \textit{pre-processing}, \textit{in-processing} and \textit{post-processing} (\Cref{fig:ai-lifecycle}).
%
\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{figures/ai-lifecycle.png}
    \caption{Fair \acs{AI} lifecycle from \cite{DBLP:conf/ijcai/CalegariCMO23}}
    \label{fig:ai-lifecycle}
\end{figure}
%
Respectively, \textit{pre-processing} involves data collection and preparation, \textit{in-processing} refers to the model training phase, and \textit{post-processing} deals with the fair evaluation of the \ac{AI} system.

Often engineers adopt reductionist approaches addressing a field that is not their own, discarding the big picture of social, economic, and institutional constraints.
%
On the other hand, socio-legal experts consider a broader range of activities and phases. They focus on ``building blocks'' for fair \ac{AI} such as risk assessment, stakeholder identification, regulatory analysis, and fundamental human rights impact assessment. In particular, with respect to fundamental rights impact assessments, these will be legally required for some \ac{AI} systems, yet no standard for implementing them has emerged so far.




\section{Practical Issues}

\subsection{What is (un)fair?}

% 1. the notion of fairness is subjective 

Fairness in \ac{AI} (and beyond) is inherently subjective, shaped by cultural values, ethical theories, and individual perspectives.
%
What one group considers fair may not align with other people’s understanding, leading to debates about determining what is fair and what is not.
%
This subjectivity and variation in viewpoints complicates efforts to develop standardized fairness metrics, as no single approach can universally capture the diverse and often conflicting notions of fairness present across different social, legal, and institutional contexts.

% 2. the notion of fairness is also context-dependent 

Beyond its subjectivity, fairness is also highly context-dependent. The same algorithm might be considered fair in one application but biased in another, depending on the societal, legal, and institutional constraints surrounding it.
%
For instance, fairness considerations in hiring algorithms differ from those in criminal justice risk assessments, necessitating tailored approaches rather than generic solutions.
%
Moving forward, privileged and unprivileged groups change depending on the application domain, as well as the fairness criteria that are taken into account.

\subsection{Bridging Perspectives}
% 3. bridging socio-legal perspective and technical perspective is difficult 

Bridging the socio-legal and technical perspectives on fairness is a significant challenge. 
%
Guidelines and descriptive methodologies exist to address fairness compliance from a social-legal perspective, but their approach offer broad guidelines without defining practical steps, leaving interpretation to technical experts (\cite{hicssfairness2025}).
%
The lack of alignment between these viewpoints makes it difficult to translate abstract fairness principles into concrete computational methods.
%
This also leads to a proliferation of metrics, each measuring slightly different aspects of fairness, reflecting the diverse priorities and domain perspectives.

% 4. socio-legal and technical perspectives speak different languages, 

A fundamental obstacle to this integration is the differing language used by socio-legal experts and technical people.
%
It is difficult to reach an agreement if even a concept or term can assume different meanings depending on the perspective.
% Legal and ethical frameworks rely on qualitative reasoning and precedent, whereas technical disciplines typically speaks about quantitative metrics
This linguistic division creates a difficult barrier to interdisciplinary collaboration, leading to misunderstandings even when working towards shared goals.


% 5. socio-legal and technical perspectives have different backgrounds

These perspectives are shaped also by distinct academic and methodological backgrounds.
%
Legal and ethical frameworks tend to be verbose and highly context-specific, relying on various interpretations and case-by-case analyses.
%
In contrast, technical disciplines prioritize concrete steps and pragmatic aspects.

% 6. lack of methodology that takes into account both perspectives

In literature, there is a lack of methodologies regarding the building of fair \ac{AI} systems. The lack is not just related to the technical perspective, but also to the socio-legal one.
%
This is enhanced by the fact that design and develop a single methodology fitting all kinds of \ac{AI} systems is not feasible, as the system requirements and constraints change depending on the context and the application domain.
%
Of course, the creation of such methodology is damaged by the multidisciplinary complexity of the problem, and should involve expertises across all the relevant fields.


% % ----------------


% You may also put some code snippet (which is NOT float by default), eg: \cref{lst:random-code}.

% \lstinputlisting[float,language=Java,label={lst:random-code}]{listings/HelloWorld.java}


%----------------------------------------------------------------------------------------
\chapter{The Meta-Methodology}\label{chap:meta-methodology}
%----------------------------------------------------------------------------------------

% 0. explaining what is a methodology and why we need it to build fair AI systems

A \textbf{methodology} is a structured framework that outlines the principles, processes, techniques and best practices used to conduct research or develop systems in a systematic and reproducible manner.
%
In this context, a well-defined methodology would be essential for ensuring fairness, as it would provide a rigorous approach to
\begin{enumerate*}[label=(\roman*)]
    \item translating socio-legal requirements into technical steps,
    \item identifying and mitigating biases, and
    \item building \texttt{fair-by-design} systems.
\end{enumerate*}
\sidenote{need to introduce the concept of \texttt{fair-by-design} systems in Background chapter}

Having a rigorous methodology would impact the development of fair \ac{AI} systems, it means that it would represent a clear way to follow, encapsulating the already existing unclear guidelines provided by the socio-legal frameworks.

% x why META-methodology
Unfortunately, factors such as multidisciplinarity, complexity, and context-dependency make it difficult to design a single methodology that fits all contexts and applications.
%
Therefore, this contribution proposes a \textbf{meta-methodology} that provides a flexible and adaptable framework for design and develop multiple methodologies instead of a single one.
%
The idea of the meta-methodology comes from the sessions of brainstorming and discussions between experts of different fields, where troubles are emerged in reaching an agreement and proceeding with clear technical steps relying on the legal requirements.

% The meta-methodology consists of the following key components:

\section{Desiderata}
In the following, are listed the desiderata that the meta-methodology should satisfy.
% 1. List the meta-methodology desiderata/requirements


\begin{enumerate}[label=\textbf{R\arabic*}, ref=R\arabic*]
    % 1.1 the methodology should consider the cultural context and the domain AI system under design
    \item\label{req:R1} \textbf{Context and Domain Awareness}: The methodology should consider the cultural context and the domain of \ac{AI} system under design.
    
    AI systems have been applied in several (and critical) use cases. For each of them, the constraints and requirements change, so through the methodology, it should be possible to understand the system domain and be context-aware.

    % 1.2 the methodology should adapt to any change in the cultural context as it evolves
    \item\label{req:R2} \textbf{Adaptability}: The methodology should adapt to any change in the cultural context as it evolves.
    
    Some context could be volatile in terms of societal norms and cultural changes, so the methodology should be able to adjust and align to new constraints.
    
    % 1.3 the methodology should assist experts in translating the social-legal requirements into practice
    \item\label{req:R3} \textbf{Requirements Translation}: The methodology should assist experts in translating the socio-legal requirements into practice.
    
    A big challenge in this field, is to understand how legal constraints can be applied, and how technical steps can be identified to satisfy the requirements. That's why the methodology should provide a mechanism assisting this phase.
    
    % 1.4 the methodology should account for both pre-existing AI systems, datasets, and algorithms, and new AI systems
    \item\label{req:R4} \textbf{Legacy and Novel Systems}: The methodology should account for both pre-existing and new \ac{AI} systems.
    
    It is reasonable that the methodology should be able to be applied to new software systems, but it would be a big lack if it could not be applied to already existing systems, remembering that there are a lot of deployed systems that, probably, are not fair.

    % 1.5 the methodology should not just provide a theoretical guideline, but also assist the AI system creation
    \item\label{req:R5} \textbf{Building the AI System}: The methodology should not just provide a theoretical guideline, but also assist the AI system creation. 
    
    This means that it is necessary a software reification of the methodology permitting to be applied practically, obtaining eventually, a fair AI system.
\end{enumerate}


% 2. Concepts
\section{Concepts}

\paragraph{The Roles.}
In the proposed methodology process, there are two main roles involved:
\begin{enumerate}
    \item \textbf{\ac{BU}}, also called \textbf{stakeholder}, who is the person commissioning the \ac{AI} system.
    \item \textbf{\ac{TU}}, who is the person with technical background, assisting the \ac{BU} in the development of the \ac{AI} system.
\end{enumerate}

With respect to \ac{BU}, it is assumed that he or she may have limited or no technical knowledge.
%
This is a common scenario in the real world, where often stakeholders are people with a specific domain expertise, but not necessarily with technical skills.
%
One of the goal of the methodology, is to provide a way to assist the \ac{BU} in the development of the \ac{AI} system, without requiring necessarily deep technical knowledge.
%
Potentially, stakeholder could even build a fair \ac{AI} system without the need of a \ac{TU}.

On the other hand, the \acl{TU}, despite is the person with technical background, is not the responsible for the entire system development.
%
Firstly, \ac{TU} must be able to assist \ac{BU} during the process to clarify any technicalities that may arise, and secondly, he or she must have some knowledge about basics of fairness.

Finally, \ac{TU} may contribute to the system development through the implementation of scripts/computational processes involved in the building of the system and integrated in the methodology.
%
In fact, the software reification of the methodology will be a tool providing APIs for technical people, in order to permit them to attach their scripts.


\paragraph{Questionnaire.}
% 2.1. integration of multiple perspectives and representing legal contraints through a Q/A
Discussions among experts from involved fields highlighted the need for a practical understanding of the domain and the cultural context of the system being designed, ensuring that it is accessible and comprehensible to people of any background.
%
The proposed approach relies on a straightforward questionnaire, which directly engages the \acl{BU} with questions regarding the system's domain.

% 2.1.1 also to represent practical steps
The questionnaire serves as a structured flow of questions and answers designed to gather essential contextual information. Depending on that, it provides practical steps to guide the development of a fair \ac{AI} system.
%
Questionnaire is not just used to collect information, it also acts as a tool to assist the \ac{BU} in making well-informed decisions. At the same time, questions represent also technical steps to be taken, addressing the socio-legal constraints in a comprehensible way.
%
This approach is central to the methodology, owing to its simplicity and versatility in capturing constraints and supporting multiple use cases.
%
The overall concept is shown in \cref{fig:concept}.

\begin{figure}
    \centering
    \includegraphics[width=0.90\linewidth]{figures/concept.pdf}
    \caption{Concept of the proposed approach to fairness engineering from \cite{hicssfairness2025}.}
    \label{fig:concept}
\end{figure}

% 2.1.2 questions designed ad-hoc from a team of multidisciplinary experts
The pool of questions and answers should be designed ad-hoc from a team of multidisciplinary experts. 
%
This is a crucial, and non-trivial, step in the methodology, as the questions should be able to capture the constraints and requirements from legal frameworks, but also to provide technicalities to be addressed in the proper way and at right time in the process.

Examples of questions that could be asked are:
\begin{itemize}
    \item ``In what area will the \ac{AI} system be applied?'' (Healthcare, Finance, Hiring, etc.)
    \item ``Do you have some AI system already in place, or are you developing an AI system?''
    \item ``Is the dataset sufficiently representative of the population where the system will be used?''
\end{itemize}
%
But also more technical questions like:
\begin{itemize}
    \item ``What are the fairness metrics that should be considered?'' (Statistical Parity Difference, Disparate Impact, etc.)
    \item ``Which are the proxies for the sensitive features?''
    \item ``Which data mitigation algorithm do you want to use?'' (Disparate Impact Remover, Learned Fair Representations, etc.)
\end{itemize}


% 2.2 Order of questions
\paragraph{Order of Questions.}
In the previous paragraph it was mentioned that the flow of questions contains generic and technical questions.
%
The questionnaire should follow a structured approach, beginning with general questions before gradually introducing more technical aspects.
%
Initially, broad and non-technical questions are asked to establish a clear understanding of the system’s domain, purpose, and the cultural or business context in which it operates.
%
As the questionnaire progresses, the questions become more specific and technical.
%
At one point it becomes mandatory to introduce technical aspects because in the end the questionnaire has to converge to the effective building of the fair \ac{AI} system.

% 2.2.1 the order of the questions is important, as the answer to a question can influence the following ones
There is another important concept related to the order of questions: the answer to a question can influence the following ones.
%
This feature is to enable the methodology to adapt to the context and asking later more tailored questions based on the previous answers.
%
Moreover, it is also useful to enrich the part of system development, as it should be possible to follow multiple paths to make an AI system fair.
%
For instance, the \acl{BU} could decide to preprocess the dataset twice, or choose to perform just in-processing mitigation.

These mechanisms lead to a more flexible and adaptable questionnaire, capable of addressing a wide range of contexts and applications, enabling also branching and joining paths in the flow.



% 2.3 Decision support mechanism (emphasis also on stakeholder awareness)
\paragraph{Decision Support.}
% 2.3.1 the Q/A mechanism is also a decision support mechanism
The methodology includes---alongside the \ac{Q/A}---a Decision Support Mechanism, aiming to simplify the process of making decisions regarding fairness-related or complex questions.
%
% 2.3.2 the Q/A mechanism is a way to make the BU aware of the fairness problem
Fairness problem should be taken into account not just by experts in the field, but also by stakeholders, as the relevance of the problem has grown significantly in the last years.
%
% 2.3.3 the Q/A mechanism does not force the BU to make decisions, but it assists him/her in making well-informed decisions
Therefore, an important goal of the methodology is to make the \ac{BU} aware of the fairness problem, and to assist him/her in making well-informed decisions.
%
In this way, the \ac{BU} can gain a deeper understanding of the topic, and can proceed with the development of the system more responsibly.
%
Importantly, the mechanism does not impose decisions but rather suggests the \ac{BU} the answer he or she probably should give.

% 2.3.4 the software also providev additional information and resources to the BU and not just questions
In addition to posing relevant questions and steps, the software provides supplementary information and resources, like charts and tables, helping the \ac{BU} to get a deeper understanding of what he is doing and to assess the fairness of the system more effectively.
\sidenote{in alcuni punti come qui gia parlo di software, prematuro?}


% 3. The Q/A mechanism
\section{The \acs{Q/A} Mechanism}

The \acf{Q/A} mechanism represents the core of this methodology, it has been the starting point to bridge the gap between socio-legal and technical perspectives.
%
It provides a structured way to ``translate'' the legal constraints into technical steps, contextualizing them in the application domain.
%
Behind the scenes, the \ac{Q/A} mechanism is a \textbf{directed graph} that represents the decision-making process.

% providing a formal description of the decision-based graph
Formally, the graph is defined as $G = (V, E)$, where $V$ is the set of nodes and $E \subseteq V \times V$ is the set of directed edges.
%
The node set $V$ consists of two distinct types: question nodes and answer nodes, such that each question node must have at least one outgoing edge leading to an answer node, and each answer node must have at least one outgoing edge towards a question node.


% 3.0 why a graph for the Q/A
\paragraph{Why a Decision-Based Graph?}
% 3.1 the graph is a way to represent the decision-making process
This structure ensures that the graph alternates between questions and answers, forming a coherent flow of a typical \ac{Q/A} session.
%
Moreover, this type of graph is particularly suitable for representing decision-making processes, as it allows for a structured flow of questions and answers, guiding the user through a series of steps.
%
The graph may contain cycles, allowing the repetition of some questions (and steps), giving even more flexibility to the process.

% 3.2 the graph is a way undertand the application context and to represent the constraints, remarking order of questions 
With the branching feature, it is possible to follow multiple paths, depending on the answers given by the \acf{BU} (and so depending on the context).
%
Remarking the order of questions, the decision-based graph effectively encodes a deterministic yet non-linear flow of questions and answers, where each answer directly influences the next question to be asked.

% 3.3 the graph can evolve and change over time (note versioning system) (reinforce the META-)
The graph is a data structure that can evolve and change easily over time, as the methodology actually is a \textbf{meta-}methodology, it is possible to create multiple versions of the graph.
%
For instance, it is possible to design different pools of questions and answers, and indeed different graphs, each one tailored to a specific context or application domain.
%
Furthermore, this flexibility enables also the possibility to adapt to any change in the cultural context taken into account, leading to a possible ``methodology versioning''.

% 3.4 types of graphs (general and project-related)
\paragraph{General Graph vs Project-Related Graph.}
So far, it has been described the general blueprint of the \ac{Q/A}: how to represent questions and answers, how the graph is structured, how the questionnaire and all its features look like.
%
However, from the \acl{BU} (and \acl{TU}) perspective, the sequence of questions seems a linear path.
%
It is intentioned that, the person involved in the process, has the feeling of just compiling a questionnaire, where all the complexity is hidden behind the scenes.
%
In \cref{fig:qa-graph-path} is shown a graphical representation of the \ac{Q/A} mechanism, where the flow of questions from users' perspective is defined by a path in the graph.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/qa-graph-path.pdf}
    \caption{
        A graphical representation of the \ac{Q/A} mechanism, viewed as a graph by experts and as a sequential path by business and technical users (from \cite{hicssfairness2025}).
    }
    \label{fig:qa-graph-path}
\end{figure}

The end user can navigate freely through the questionnaire, answering questions and returning to previous ones in case of need.
%
Of course in this way it is possible to change the path, and so the flow of future questions.



% 4. Automation
\section{Automation}

At this stage, it is yet vague how the methodology proposed can inject fairness measures and practical steps into the development process.
%
Here is the point where \acf{TU} contributes to the process, by implementing scripts and computational operations that are eventually integrated into the final system.
%
Said that, \acp{TU} play an important role because, regardless of the complexity and variety of the needed scripts, such scripts can change case by case.
%
Moreover, \ac{TU} is still useful as source of technical knowledge and assistance for the \acf{BU}.

However, while many activities performed by technical users are specific to their respective organizations, certain tasks are generalizable enough to be automated directly by the implemented methodology.
%
Relevant examples of this, are the computation of fairness metrics and the identification of biases in datasets.
%
These, in fact, are enough consolidated to be automated and integrated into the methodology.
%
Rather than requiring individual technical users to develop their own solutions from scratch, the system itself can integrate these capabilities as built-in system-level functions, ensuring consistency, efficiency, and reliability across different projects.

The reification of the meta-methodology should be purposefully designed to facilitate this progression toward greater automation. 
%
When certain actions--—such as evaluating responses or detecting biases--—are widely applicable rather than organization-specific, they can be implemented as reusable system-level solutions.
%
This eliminates redundancy, reducing the need for technical users to repeatedly address the same challenges independently.

These scripts to be injected to the methodology, can be provided by methodology implementation itself, developed by technical users within organizations, or contributed by third-party developers.
%
This flexible approach ensures that automation capabilities can expand over time, adapting to emerging best practices.
%
In the early stages of system adoption, technical users may handle certain tasks manually, but as the methodology matures, these tasks can gradually be automated.

% 4.x in this way we can provide also technical steps
Technically, these scripts can be attached easily to the  software implementation of such methodology, and they can be triggered whenever some kind of events occur, like the answer to a question, or termination of another computation.

% TODO: Strengths and Limitations (pros and cons of the methodology)
% here or at the end?





%----------------------------------------------------------------------------------------
\chapter{Design}\label{chap:design}
%----------------------------------------------------------------------------------------

\section{Architecture}






%----------------------------------------------------------------------------------------
\chapter{Implementation}\label{chap:implementation}
%----------------------------------------------------------------------------------------





%----------------------------------------------------------------------------------------
\chapter{Conclusions}
\label{chap:conclusions}
%----------------------------------------------------------------------------------------



%----------------------------------------------------------------------------------------
% BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\backmatter

% \nocite{*} % Remove this as soon as you have the first citation

\bibliographystyle{alpha}
\bibliography{bibliography}

\begin{acknowledgements} % this is optional
Optional. Max 1 page.
\end{acknowledgements}

\end{document}
